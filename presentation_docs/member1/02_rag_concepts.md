# ğŸ§  KhÃ¡i Niá»‡m RAG (Retrieval-Augmented Generation)

## Má»¥c tiÃªu há»c táº­p
Sau khi Ä‘á»c tÃ i liá»‡u nÃ y, báº¡n sáº½ hiá»ƒu:
- RAG lÃ  gÃ¬ vÃ  táº¡i sao cáº§n RAG
- CÃ¡c thÃ nh pháº§n cá»§a RAG pipeline
- Æ¯u nhÆ°á»£c Ä‘iá»ƒm so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c
- CÃ¡ch RAG hoáº¡t Ä‘á»™ng trong dá»± Ã¡n

---

## 1. RAG lÃ  gÃ¬?

### 1.1 Äá»‹nh nghÄ©a
**RAG (Retrieval-Augmented Generation)** lÃ  ká»¹ thuáº­t káº¿t há»£p:
- **Retrieval**: TÃ¬m kiáº¿m thÃ´ng tin tá»« knowledge base
- **Generation**: Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn thÃ´ng tin tÃ¬m Ä‘Æ°á»£c

### 1.2 Ã tÆ°á»Ÿng cá»‘t lÃµi
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Without RAG                            â”‚
â”‚                                                          â”‚
â”‚   User Question â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º LLM â”€â”€â”€â”€â”€â–º Answer â”‚
â”‚                    (Limited/Outdated Knowledge)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     With RAG                              â”‚
â”‚                                                          â”‚
â”‚   User Question â”€â”€â”€â–º Retrieve â”€â”€â”€â–º Context + Question    â”‚
â”‚                        â”‚               â”‚                 â”‚
â”‚                   Knowledge Base       â–¼                 â”‚
â”‚                        â”‚            LLM â”€â”€â”€â”€â–º Answer     â”‚
â”‚                        â”‚          (With citations)       â”‚
â”‚                   Vector Database                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Táº¡i sao cáº§n RAG?

### 2.1 Háº¡n cháº¿ cá»§a LLM thuáº§n tÃºy
| Váº¥n Ä‘á» | MÃ´ táº£ |
|--------|-------|
| **Knowledge Cutoff** | LLM chá»‰ biáº¿t data Ä‘áº¿n thá»i Ä‘iá»ƒm training |
| **Hallucination** | LLM cÃ³ thá»ƒ bá»‹a thÃ´ng tin sai |
| **No Citation** | KhÃ´ng thá»ƒ trÃ­ch dáº«n nguá»“n cá»¥ thá»ƒ |
| **Domain Knowledge** | Thiáº¿u kiáº¿n thá»©c chuyÃªn ngÃ nh (vÃ­ dá»¥: luáº­t VN) |

### 2.2 RAG giáº£i quyáº¿t nhÆ° tháº¿ nÃ o?
| Váº¥n Ä‘á» | Giáº£i phÃ¡p RAG |
|--------|---------------|
| Knowledge Cutoff | Cáº­p nháº­t knowledge base má»›i khÃ´ng cáº§n retrain |
| Hallucination | LLM chá»‰ tráº£ lá»i dá»±a trÃªn context Ä‘Æ°á»£c cung cáº¥p |
| No Citation | KÃ¨m theo source document vÃ  page number |
| Domain Knowledge | Inject domain-specific documents vÃ o context |

---

## 3. RAG Pipeline Chi Tiáº¿t

### 3.1 Offline Phase (Indexing)
Chuyá»ƒn Ä‘á»•i documents thÃ nh vector vÃ  lÆ°u trá»¯:

```
PDF/DOCX Files
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Loader    â”‚  â† Load file, extract text
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Splitter   â”‚  â† Chia thÃ nh chunks nhá» (1000 chars)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embedding  â”‚  â† Chuyá»ƒn text â†’ vector (768 dimensions)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FAISS     â”‚  â† LÆ°u trá»¯ vÃ  index vectors
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Online Phase (Query)
Xá»­ lÃ½ cÃ¢u há»i vÃ  táº¡o cÃ¢u tráº£ lá»i:

```
User Query: "Thai sáº£n Ä‘Æ°á»£c nghá»‰ bao nhiÃªu ngÃ y?"
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embedding  â”‚  â† Query â†’ vector
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retrieval  â”‚  â† TÃ¬m top-K vectors tÆ°Æ¡ng tá»±
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Context = [                            â”‚
â”‚    "Äiá»u 139: Lao Ä‘á»™ng ná»¯ Ä‘Æ°á»£c nghá»‰     â”‚
â”‚    trÆ°á»›c vÃ  sau khi sinh con lÃ  6       â”‚
â”‚    thÃ¡ng..." (Trang 45)                 â”‚
â”‚  ]                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     LLM     â”‚  â† Context + Question â†’ Answer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
"Theo Äiá»u 139 Bá»™ luáº­t Lao Ä‘á»™ng, ngÆ°á»i lao Ä‘á»™ng ná»¯
Ä‘Æ°á»£c nghá»‰ thai sáº£n 6 thÃ¡ng. [Nguá»“n: file.pdf, Trang 45]"
```

---

## 4. CÃ¡c khÃ¡i niá»‡m quan trá»ng

### 4.1 Embedding
- **Äá»‹nh nghÄ©a**: Biá»ƒu diá»…n text dÆ°á»›i dáº¡ng vector sá»‘ há»c
- **Má»¥c Ä‘Ã­ch**: So sÃ¡nh semantic similarity giá»¯a cÃ¡c vÄƒn báº£n
- **Trong dá»± Ã¡n**: Sá»­ dá»¥ng `vietnamese-bi-encoder` (768 dimensions)

```python
# VÃ­ dá»¥ conceptual
text = "Thai sáº£n Ä‘Æ°á»£c nghá»‰ bao nhiÃªu ngÃ y?"
vector = embed(text)  # â†’ [0.12, -0.45, ..., 0.78]  (768 values)
```

### 4.2 Chunking
- **Táº¡i sao cáº§n**: LLM cÃ³ giá»›i háº¡n context window
- **Chiáº¿n lÆ°á»£c**: Chia document thÃ nh chunks ~1000 characters
- **Overlap**: 200 characters Ä‘á»ƒ giá»¯ ngá»¯ cáº£nh liÃªn tá»¥c

```
Document: "Äiá»u 139... (1000 chars) ... Äiá»u 140... (1000 chars)"
             â”‚                          â”‚
             â–¼                          â–¼
         Chunk 1                    Chunk 2
    (overlap 200 chars vá»›i chunk 2)
```

### 4.3 Similarity Search
- **Cosine Similarity**: Äo gÃ³c giá»¯a 2 vectors
- **L2 Distance**: Khoáº£ng cÃ¡ch Euclidean
- **Top-K**: Láº¥y K documents cÃ³ similarity cao nháº¥t

```
Query Vector: [0.1, 0.2, 0.3]

Document Vectors:
- Doc A: [0.11, 0.19, 0.31]  â† Similarity: 0.99 âœ“ Top-1
- Doc B: [0.5, -0.1, 0.2]   â† Similarity: 0.45
- Doc C: [-0.3, 0.0, 0.1]   â† Similarity: 0.12
```

### 4.4 Context Window
- **Giá»›i háº¡n LLM**: Sá»‘ lÆ°á»£ng token tá»‘i Ä‘a LLM cÃ³ thá»ƒ nháº­n
- **Trade-off**: Nhiá»u context = nhiá»u thÃ´ng tin nhÆ°ng cháº­m hÆ¡n
- **Trong dá»± Ã¡n**: Láº¥y top 10 documents, tá»•ng ~2000-3000 tokens

---

## 5. So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p

| TiÃªu chÃ­ | RAG | Fine-tuning | Prompt Engineering |
|----------|-----|-------------|-------------------|
| **Cost** | Tháº¥p | Cao | Tháº¥p |
| **Update Knowledge** | Dá»… (thÃªm docs) | KhÃ³ (retrain) | KhÃ´ng thá»ƒ |
| **Citation** | âœ… CÃ³ | âŒ KhÃ´ng | âŒ KhÃ´ng |
| **Domain Accuracy** | Cao | Cao | Trung bÃ¬nh |
| **Hallucination** | Tháº¥p | Trung bÃ¬nh | Cao |
| **Complexity** | Trung bÃ¬nh | Cao | Tháº¥p |

---

## 6. RAG trong dá»± Ã¡n AI Legal Assistant

### 6.1 Äáº·c thÃ¹ domain PhÃ¡p luáº­t
- **YÃªu cáº§u chÃ­nh xÃ¡c**: Tráº£ lá»i sai cÃ³ thá»ƒ gÃ¢y háº­u quáº£ nghiÃªm trá»ng
- **Cáº§n trÃ­ch dáº«n**: NgÆ°á»i dÃ¹ng muá»‘n verify thÃ´ng tin
- **Cáº­p nháº­t thÆ°á»ng xuyÃªn**: Luáº­t thay Ä‘á»•i theo nÄƒm

### 6.2 Customizations
| Component | Customization |
|-----------|---------------|
| Embedding Model | `vietnamese-bi-encoder` - optimized cho tiáº¿ng Viá»‡t |
| Prompt | IRAC structure (Issue-Rule-Analysis-Conclusion) |
| Router | PhÃ¢n loáº¡i LEGAL vs GENERAL intent |
| Rewriter | Viáº¿t láº¡i cÃ¢u há»i follow-up thÃ nh standalone |

### 6.3 Prompt Engineering cho Legal
```python
QA_SYSTEM_PROMPT = """
Báº¡n lÃ  Cá»‘ váº¥n PhÃ¡p lÃ½ AI cáº¥p cao...

QUY TRÃŒNH TÆ¯ DUY (Chain of Thought):
1. Äá»c ká»¹ cÃ¢u há»i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh váº¥n Ä‘á» phÃ¡p lÃ½ cá»‘t lÃµi
2. RÃ  soÃ¡t [TÃ€I LIá»†U THAM KHáº¢O] Ä‘á»ƒ tÃ¬m Äiá»u khoáº£n liÃªn quan
3. XÃ¢y dá»±ng cÃ¢u tráº£ lá»i theo cáº¥u trÃºc IRAC

NGUYÃŠN Táº®C Báº®T BUá»˜C:
1. TUYá»†T Äá»I KHÃ”NG Bá»ŠA Äáº¶T (Hallucination)
2. CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« Context
3. LUÃ”N trÃ­ch dáº«n nguá»“n cá»¥ thá»ƒ
"""
```

---

## 7. Äiá»ƒm máº¡nh cá»§a RAG trong dá»± Ã¡n nÃ y

> [!TIP]
> **Highlight khi thuyáº¿t trÃ¬nh:**
> 1. **Accuracy + Citation**: Má»i cÃ¢u tráº£ lá»i Ä‘á»u cÃ³ nguá»“n verify
> 2. **Easy Update**: ThÃªm luáº­t má»›i chá»‰ cáº§n copy file PDF vÃ o folder
> 3. **Vietnamese Optimized**: Embedding model Ä‘Æ°á»£c train cho tiáº¿ng Viá»‡t
> 4. **Conversational**: Há»— trá»£ há»i tiáº¿p (follow-up questions)

---

## 8. Limitations & Trade-offs

| Limitation | Mitigation |
|------------|------------|
| Retrieval quality depends on chunking | Overlap 200 chars Ä‘á»ƒ giá»¯ context |
| Top-K might miss relevant docs | K=10 Ä‘á»ƒ tÄƒng recall |
| Embedding model khÃ´ng perfect | DÃ¹ng model specialized cho Vietnamese |
| LLM cÃ³ thá»ƒ ignore context | Strict prompt engineering |

---

## TÃ i liá»‡u liÃªn quan
- [Overview Architecture](./01_overview_architecture.md)
- [Tech Stack Summary](./03_tech_stack_summary.md)
