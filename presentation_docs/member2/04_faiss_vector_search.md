# ğŸ” FAISS Vector Search

## Má»¥c tiÃªu há»c táº­p
Sau khi Ä‘á»c tÃ i liá»‡u nÃ y, báº¡n sáº½ hiá»ƒu:
- FAISS lÃ  gÃ¬ vÃ  táº¡i sao cáº§n vector database
- CÃ¡c loáº¡i index (Flat, IVF, IVFPQ)
- Trade-offs giá»¯a accuracy vÃ  speed
- CÃ¡ch cáº¥u hÃ¬nh FAISS trong dá»± Ã¡n

---

## 1. FAISS lÃ  gÃ¬?

### 1.1 Äá»‹nh nghÄ©a
**FAISS (Facebook AI Similarity Search)** lÃ  thÆ° viá»‡n tÃ¬m kiáº¿m vector hiá»‡u quáº£, phÃ¡t triá»ƒn bá»Ÿi Facebook AI Research.

### 1.2 Táº¡i sao cáº§n Vector Database?

| Traditional DB | Vector DB (FAISS) |
|----------------|-------------------|
| Keyword search | Semantic search |
| Exact match | Similarity match |
| "thai sáº£n" | "nghá»‰ Ä‘áº»", "maternity leave" |
| O(n) scan hoáº·c index | O(1) â†’ O(log n) vá»›i index |

### 1.3 Use Case trong dá»± Ã¡n

```
User Query: "Nghá»‰ sinh con Ä‘Æ°á»£c máº¥y thÃ¡ng?"
      â”‚
      â–¼ Embedding
[0.12, -0.34, ..., 0.78]  (query vector)
      â”‚
      â–¼ FAISS Search
      â”‚
Find Top-10 similar vectors from 1500 chunks
      â”‚
      â–¼
[Chunk vá» Äiá»u 139], [Chunk vá» thai sáº£n], ...
```

---

## 2. FAISS Index Types

### 2.1 Index Types trong dá»± Ã¡n

| Type | Factory String | MÃ´ táº£ |
|------|----------------|-------|
| **Flat** | `"Flat"` | Brute-force exact search |
| **IVF** | `"IVF64,Flat"` | Clustering-based approximate |
| **IVFPQ** | `"IVF64,PQ48x8"` | Clustering + Product Quantization |

### 2.2 Visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INDEX TYPES                           â”‚
â”‚                                                             â”‚
â”‚   FLAT                    IVF                    IVFPQ      â”‚
â”‚   â—â—â—â—â—â—â—â—               â”Œâ”€â”€â—â—â—â”                â”Œâ”€â”€â—‹â—‹â—‹â”    â”‚
â”‚   â—â—â—â—â—â—â—â—               â”‚     â”‚                â”‚     â”‚    â”‚
â”‚   â—â—â—â—â—â—â—â—               â””â”€â”€â—â—â—â”˜ Cluster 1      â””â”€â”€â—‹â—‹â—‹â”˜    â”‚
â”‚   (all dots)             â”Œâ”€â”€â—â—â—â”                â”Œâ”€â”€â—‹â—‹â—‹â”    â”‚
â”‚                          â”‚     â”‚                â”‚     â”‚    â”‚
â”‚   Search ALL             â””â”€â”€â—â—â—â”˜ Cluster 2      â””â”€â”€â—‹â—‹â—‹â”˜    â”‚
â”‚                          (search some clusters) (compressed)â”‚
â”‚                                                             â”‚
â”‚   Speed: Slow            Speed: Fast            Speed: Fastestâ”‚
â”‚   Accuracy: 100%         Accuracy: ~96%         Accuracy: ~92%â”‚
â”‚   Memory: Large          Memory: Medium         Memory: Small â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Flat Index (Exact Search)

### 3.1 Hoáº¡t Ä‘á»™ng

```
Query Vector â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Compare vá»›i Táº¤T Cáº¢ vectors â”‚
                â”‚  trong database             â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                        Top-K Results (100% accurate)
```

### 3.2 Complexity

| Metric | Value |
|--------|-------|
| Search | O(n Ã— d) |
| Memory | O(n Ã— d) |
| Accuracy | 100% |

Vá»›i n = 1500 vectors, d = 768:
- ~1.15M comparisons per query

### 3.3 Khi nÃ o dÃ¹ng?
- Dataset nhá» (< 10K vectors)
- Cáº§n 100% accuracy
- Latency khÃ´ng critical

---

## 4. IVF Index (Inverted File)

### 4.1 Ã tÆ°á»Ÿng: Clustering

```
Training Phase:               Search Phase:
                              
K-means clustering            1. Find nearest cluster(s)
    on vectors                2. Search only within those
        â”‚                            clusters
        â–¼                            
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        Query â”€â”€â–º Cluster 3 â”€â”€â–º Top-K
â”‚  64 clusters       â”‚                 (skip other clusters)
â”‚  â—â”€â”€â”  â—â”€â”€â”  â—â”€â”€â” â”‚
â”‚  â—  â”‚  â—  â”‚  â—  â”‚ â”‚
â”‚  â—â”€â”€â”˜  â—â”€â”€â”˜  â—â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Parameters

| Parameter | Meaning | Trong dá»± Ã¡n |
|-----------|---------|-------------|
| **nlist** | Sá»‘ clusters | 64 |
| **nprobe** | Clusters to search | 8-32 |

### 4.3 Trade-off: nprobe

```
nprobe = 1:   Search 1.5% of data    â†’ Fast, Low recall
nprobe = 8:   Search 12.5% of data   â†’ Balanced
nprobe = 32:  Search 50% of data     â†’ Slow, High recall
nprobe = 64:  Search 100% of data    â†’ Same as Flat
```

### 4.4 Benchmark Results (1530 vectors)

| nprobe | Latency | Recall@10 |
|--------|---------|-----------|
| 1 | 88ms | 33.3% |
| 8 | 87ms | 73.3% |
| 32 | 94ms | 96.7% âœ“ |
| 64 | 93ms | 100% |

**Recommendation**: nprobe=32 cho 97% recall vá»›i minimal latency impact

---

## 5. IVFPQ (IVF + Product Quantization)

### 5.1 Ã tÆ°á»Ÿng: Compression

```
Original Vector (768D, 3KB):
[0.12, -0.34, 0.56, ... , 0.78]
        â”‚
        â–¼ Product Quantization
        â”‚
Compressed (48 bytes):
[code1, code2, ..., code48]

Memory savings: ~98%
```

### 5.2 Khi nÃ o dÃ¹ng?
- Dataset ráº¥t lá»›n (100K+ vectors)
- Memory constrained
- CÃ³ thá»ƒ cháº¥p nháº­n ~92% accuracy

### 5.3 Trong dá»± Ã¡n
```
VECTOR_INDEX_TYPE=ivfpq
Factory: "IVF64,PQ48x8"
         â†‘     â†‘
         â”‚     PQ48: 768/48 = 16 dimensions per subvector
         â”‚     x8: 8-bit codes
         nlist=64 clusters
```

---

## 6. Cáº¥u hÃ¬nh trong dá»± Ã¡n

### 6.1 Environment Variables (.env)

```bash
# Index type
VECTOR_INDEX_TYPE=ivf    # flat, ivf, ivfpq

# IVF parameters
IVF_NLIST=64            # Number of clusters
IVF_NPROBE=32           # Clusters to search at query time
```

### 6.2 Config Code

```python
# src/config.py
class AppConfig:
    VECTOR_INDEX_TYPE = os.getenv("VECTOR_INDEX_TYPE", "flat")
    IVF_NLIST = int(os.getenv("IVF_NLIST", "64"))
    IVF_NPROBE = int(os.getenv("IVF_NPROBE", "8"))
    
    @classmethod
    def get_index_factory_string(cls) -> str:
        if cls.VECTOR_INDEX_TYPE == "flat":
            return "Flat"
        elif cls.VECTOR_INDEX_TYPE == "ivf":
            return f"IVF{cls.IVF_NLIST},Flat"
        elif cls.VECTOR_INDEX_TYPE == "ivfpq":
            return f"IVF{cls.IVF_NLIST},PQ48x8"
```

---

## 7. Index Creation Flow

### 7.1 Code

```python
# src/ingestion/indexer.py

def _create_faiss_index(docs, embeddings, chunk_ids):
    # 1. Generate embeddings
    texts = [doc.page_content for doc in docs]
    embeddings_matrix = np.array(embeddings.embed_documents(texts))
    dimension = embeddings_matrix.shape[1]  # 768
    
    # 2. Create index using factory
    factory_string = AppConfig.get_index_factory_string()
    index = faiss.index_factory(dimension, factory_string, faiss.METRIC_L2)
    
    # 3. Train if IVF
    if not index.is_trained:
        logger.info("Training IVF index...")
        index.train(embeddings_matrix)
    
    # 4. Add vectors
    index.add(embeddings_matrix)
    
    # 5. Wrap with LangChain FAISS
    vector_store = FAISS(
        embedding_function=embeddings,
        index=index,
        docstore=InMemoryDocstore(docstore_dict),
        index_to_docstore_id=index_to_docstore_id
    )
    
    return vector_store
```

### 7.2 Training Requirements

```
IVF64 training requires:
- Minimum: 64 vectors (= nlist)
- Recommended: 64 Ã— 39 = 2,496 vectors

If not enough vectors:
â†’ Fallback to Flat index automatically
```

---

## 8. Query Time Configuration

### 8.1 Set nprobe at Runtime

```python
# src/rag_engine/retriever.py

def set_search_mode(self, mode: str):
    ivf_index = self._get_ivf_index(index)
    
    mode_config = {
        "quality": ivf_index.nlist,  # 64 - search all
        "balanced": 8,               # 12.5% of clusters
        "speed": 2,                  # 3% of clusters
    }
    
    ivf_index.nprobe = mode_config[mode]
```

### 8.2 UI Selection

```python
# app.py
search_mode = st.radio(
    "Chá»n cháº¿ Ä‘á»™:",
    options=["balanced", "quality", "speed"],
    format_func=lambda x: {
        "quality": "ğŸ¯ ChÃ­nh xÃ¡c cao",
        "balanced": "âš–ï¸ CÃ¢n báº±ng (Khuyáº¿n nghá»‹)",
        "speed": "ğŸš€ Tá»‘c Ä‘á»™ cao"
    }[x]
)
```

---

## 9. Similarity Search

### 9.1 Search Flow

```python
# src/rag_engine/retriever.py

def get_relevant_docs(self, query: str, k: int = 10):
    # LangChain wrapper handles:
    # 1. Embed query
    # 2. Call FAISS similarity_search
    # 3. Map results back to Documents
    
    docs = self.vector_store.similarity_search(query, k=k)
    return docs
```

### 9.2 Under the hood

```python
# What LangChain does:
query_vector = embeddings.embed_query(query)
distances, indices = index.search(query_vector, k=10)
# distances: [0.12, 0.15, 0.18, ...]  (L2 distances)
# indices: [42, 156, 789, ...]        (document IDs)
```

---

## 10. Storage

### 10.1 Files Generated

```
data/vector_store/
â”œâ”€â”€ index.faiss              # FAISS binary index (~9MB for 1500 vectors)
â”œâ”€â”€ index.pkl                # LangChain docstore mapping
â””â”€â”€ indexing_metadata.json   # File tracking metadata
```

### 10.2 Memory Usage

| Index Type | Memory (1500 vectors, 768D) |
|------------|----------------------------|
| Flat | ~4.6 MB |
| IVF | ~4.8 MB (+ cluster centroids) |
| IVFPQ | ~2.5 MB (compressed) |

---

## 11. Comparison Summary

| Metric | Flat | IVF | IVFPQ |
|--------|------|-----|-------|
| **Accuracy** | 100% | 96%+ | 92%+ |
| **Speed (1500 vec)** | 138ms | 93ms | 85ms |
| **Speed (100K vec)** | 5s+ | 200ms | 100ms |
| **Memory** | Lá»›n | Trung bÃ¬nh | Nhá» |
| **Complexity** | ÄÆ¡n giáº£n | Cáº§n training | Phá»©c táº¡p |

---

## 12. Key Takeaways

> [!IMPORTANT]
> **Äiá»ƒm nháº¥n khi thuyáº¿t trÃ¬nh:**
> 1. **FAISS = Vector similarity search library** tá»« Facebook AI
> 2. **3 index types**: Flat (exact), IVF (clustering), IVFPQ (compressed)
> 3. **IVF tradeoff**: nprobe cao = accurate hÆ¡n nhÆ°ng cháº­m hÆ¡n
> 4. **Trong dá»± Ã¡n**: IVF64 vá»›i nprobe=32 cho 97% recall

---

## TÃ i liá»‡u liÃªn quan
- [Ingestion Pipeline](./01_ingestion_pipeline.md)
- [Embedding Models](./03_embedding_models.md)
