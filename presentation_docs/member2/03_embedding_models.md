# ğŸ§® Embedding Models - Chuyá»ƒn Text thÃ nh Vector

## Má»¥c tiÃªu há»c táº­p
Sau khi Ä‘á»c tÃ i liá»‡u nÃ y, báº¡n sáº½ hiá»ƒu:
- Embedding lÃ  gÃ¬ vÃ  hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o
- Táº¡i sao cáº§n model embedding cho tiáº¿ng Viá»‡t
- vietnamese-bi-encoder vÃ  cÃ¡c Ä‘áº·c Ä‘iá»ƒm

---

## 1. Embedding lÃ  gÃ¬?

### 1.1 Äá»‹nh nghÄ©a
**Text Embedding** lÃ  quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i vÄƒn báº£n thÃ nh vector sá»‘ há»c trong khÃ´ng gian nhiá»u chiá»u.

```
Input Text: "Thai sáº£n Ä‘Æ°á»£c nghá»‰ bao nhiÃªu ngÃ y?"
     â”‚
     â–¼ Embedding Model
     â”‚
Output Vector: [0.12, -0.34, 0.56, ..., 0.78]
               â†‘
               768 dimensions
```

### 1.2 Táº¡i sao cáº§n Embedding?

| Váº¥n Ä‘á» | Giáº£i phÃ¡p |
|--------|-----------|
| Machine khÃ´ng hiá»ƒu text | Chuyá»ƒn text â†’ sá»‘ |
| So sÃ¡nh semantic similarity | Vectors gáº§n nhau = Ã½ nghÄ©a giá»‘ng nhau |
| Efficient search | Vector search nhanh hÆ¡n text search |

### 1.3 Semantic Similarity

```
Vector Space Visualization (simplified 2D):

                    â†‘
        "nghá»‰ thai sáº£n"  â€¢ "maternity leave"
                         â€¢
                    â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
                         â€¢
        "nghá»‰ hÃ¨"    â€¢   "summer vacation"
                         
Vectors gáº§n nhau cÃ³ nghÄ©a tÆ°Æ¡ng tá»±!
```

---

## 2. Embedding Model Types

### 2.1 Single Encoder (BERT-based)
```
Query:    "thai sáº£n" â”€â”€â–º Encoder â”€â”€â–º Vector_Q
Document: "nghá»‰ Ä‘áº»"  â”€â”€â–º Encoder â”€â”€â–º Vector_D
                              â†“
                    cosine_sim(Vector_Q, Vector_D) = 0.87
```
**NhÆ°á»£c Ä‘iá»ƒm**: Cháº­m khi cáº§n encode cáº£ query vÃ  documents realtime

### 2.2 Bi-Encoder (Sentence Transformers)
```
Offline: Encode táº¥t cáº£ documents â”€â”€â–º Store vectors in FAISS
Online:  Encode query only      â”€â”€â–º Search against stored vectors
```
**Æ¯u Ä‘iá»ƒm**: Nhanh - chá»‰ encode query khi search

### 2.3 Cross-Encoder
```
Query + Document â”€â”€â–º [CLS] query [SEP] document [SEP] â”€â”€â–º Score
```
**Æ¯u Ä‘iá»ƒm**: Accurate nháº¥t
**NhÆ°á»£c Ä‘iá»ƒm**: Cháº­m - pháº£i encode má»—i cáº·p (query, doc)

**Trong dá»± Ã¡n chÃºng ta dÃ¹ng**: âœ… **Bi-Encoder**

---

## 3. vietnamese-bi-encoder

### 3.1 Model Info

| Attribute | Value |
|-----------|-------|
| **Name** | `bkai-foundation-models/vietnamese-bi-encoder` |
| **Type** | Bi-Encoder (Sentence Transformer) |
| **Dimensions** | 768 |
| **Language** | Vietnamese optimized |
| **Base Model** | XLM-RoBERTa |
| **Source** | HuggingFace |

### 3.2 Táº¡i sao chá»n model nÃ y?

| Reason | Explanation |
|--------|-------------|
| **Vietnamese specialized** | Trained trÃªn Vietnamese data |
| **Bi-Encoder** | Fast retrieval - encode 1 láº§n, search nhiá»u láº§n |
| **768D** | Industry standard, compatible vá»›i FAISS |
| **Open source** | Miá»…n phÃ­, cháº¡y local |
| **BKAI** | Nguá»“n uy tÃ­n - VN AI lab |

### 3.3 Comparison vá»›i alternatives

| Model | Lang | Dims | Speed | VN Quality |
|-------|------|------|-------|------------|
| **vietnamese-bi-encoder** | VI | 768 | Fast | â­â­â­â­â­ |
| multilingual-e5-base | Multi | 768 | Fast | â­â­â­ |
| sentence-transformers | EN | 768 | Fast | â­â­ |
| OpenAI text-embedding-3 | Multi | 3072 | API | â­â­â­â­ |

---

## 4. CÃ¡ch sá»­ dá»¥ng trong dá»± Ã¡n

### 4.1 Initialization

```python
# src/ingestion/indexer.py & src/rag_engine/retriever.py

from langchain_huggingface import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="bkai-foundation-models/vietnamese-bi-encoder",
    model_kwargs={'device': 'cpu'},  # hoáº·c 'cuda' náº¿u cÃ³ GPU
    encode_kwargs={'normalize_embeddings': True}
)
```

### 4.2 Parameters

| Parameter | Value | Explanation |
|-----------|-------|-------------|
| `model_name` | string | HuggingFace model path |
| `device` | 'cpu' | Cháº¡y trÃªn CPU (production) |
| `normalize_embeddings` | True | L2 normalize â†’ cosine similarity |

### 4.3 Encoding Text

```python
# Single text
vector = embeddings.embed_query("thai sáº£n Ä‘Æ°á»£c nghá»‰ máº¥y thÃ¡ng?")
# Returns: List[float] with 768 values

# Batch texts (for indexing)
texts = ["text1", "text2", "text3"]
vectors = embeddings.embed_documents(texts)
# Returns: List[List[float]] - 3 vectors, each 768 dims
```

---

## 5. Embedding Process in RAG

### 5.1 Indexing Phase (Offline)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1500 Chunks   â”‚
â”‚  (text strings) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ embed_documents â”‚
â”‚   (batch mode)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1500 Vectors   â”‚
â”‚ (768D each)     â”‚
â”‚  ~9MB in FAISS  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Query Phase (Online)

```
User Query: "Thai sáº£n Ä‘Æ°á»£c nghá»‰ bao nhiÃªu ngÃ y?"
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  embed_query  â”‚
            â”‚  (~80-100ms)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            [0.12, -0.34, ..., 0.78]  (768D vector)
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ FAISS Search  â”‚  â† cosine similarity
            â”‚  (~10-20ms)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            Top 10 similar chunks
```

---

## 6. Performance Benchmarks

### 6.1 Trong dá»± Ã¡n

| Metric | Value |
|--------|-------|
| Cold start (first load) | ~15-17s |
| Query embedding | ~80-100ms |
| Batch embedding (1000 texts) | ~8-10s |
| Memory usage | ~1.5GB |

### 6.2 Tá»‘i Æ°u Cold Start

```python
# app.py uses @st.cache_resource to cache model
@st.cache_resource(show_spinner="Äang khá»Ÿi Ä‘á»™ng Model & Index...")
def get_retriever():
    return SemanticRetriever()  # Loads embedding model once
```

**Káº¿t quáº£**: 
- First load: ~17s
- Subsequent loads: <1s (cached)

---

## 7. Vector Normalization

### 7.1 Táº¡i sao normalize?

```python
encode_kwargs={'normalize_embeddings': True}
```

**L2 Normalization**: Vector â†’ unit vector (length = 1)

```
Original:   [3, 4]        â†’ length = 5
Normalized: [0.6, 0.8]    â†’ length = 1
```

### 7.2 Lá»£i Ã­ch

| Benefit | Explanation |
|---------|-------------|
| Cosine = Dot Product | TÃ­nh toÃ¡n nhanh hÆ¡n |
| Fair comparison | Vectors cÃ¹ng scale |
| FAISS optimization | Sá»­ dá»¥ng IndexFlatIP thay vÃ¬ IndexFlatL2 |

---

## 8. Common Issues

### 8.1 Out of Memory
```python
# Váº¥n Ä‘á»: Encode quÃ¡ nhiá»u texts cÃ¹ng lÃºc
# Giáº£i phÃ¡p: Batch processing
batch_size = 100
for i in range(0, len(texts), batch_size):
    batch = texts[i:i+batch_size]
    vectors = embeddings.embed_documents(batch)
```

### 8.2 Slow First Query
```python
# Váº¥n Ä‘á»: Model loading cháº­m
# Giáº£i phÃ¡p: Pre-load khi app starts
@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(...)
```

### 8.3 Language Mismatch
```python
# Váº¥n Ä‘á»: DÃ¹ng English model cho Vietnamese text
# Giáº£i phÃ¡p: DÃ¹ng vietnamese-bi-encoder
# DON'T: "sentence-transformers/all-MiniLM-L6-v2"
# DO:    "bkai-foundation-models/vietnamese-bi-encoder"
```

---

## 9. Embedding Dimension Trade-offs

| Dimensions | Storage | Search Speed | Quality |
|------------|---------|--------------|---------|
| 384 | Nhá» | Nhanh | Lower |
| **768** | Trung bÃ¬nh | CÃ¢n báº±ng | Good |
| 1024+ | Lá»›n | Cháº­m hÆ¡n | Higher |

**Trong dá»± Ã¡n**: 768D lÃ  sweet spot

---

## 10. Code trong dá»± Ã¡n

### 10.1 Indexer (Ingestion)
```python
# src/ingestion/indexer.py
class VectorIndexer:
    @staticmethod
    def _get_embeddings():
        logger.info(f"Loading embedding model: {AppConfig.EMBEDDING_MODEL_NAME}")
        return HuggingFaceEmbeddings(
            model_name=AppConfig.EMBEDDING_MODEL_NAME,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
```

### 10.2 Retriever (Query Time)
```python
# src/rag_engine/retriever.py
class SemanticRetriever:
    def __init__(self):
        self.embeddings = HuggingFaceEmbeddings(
            model_name=AppConfig.EMBEDDING_MODEL_NAME,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        self.vector_store = self._load_vector_store()
```

---

## 11. Key Takeaways

> [!IMPORTANT]
> **Äiá»ƒm nháº¥n khi thuyáº¿t trÃ¬nh:**
> 1. **Embedding = Text â†’ Vector** Ä‘á»ƒ so sÃ¡nh semantic similarity
> 2. **Bi-Encoder**: Fast - encode documents offline, chá»‰ encode query online
> 3. **vietnamese-bi-encoder**: Optimized cho tiáº¿ng Viá»‡t
> 4. **768 dimensions**: Industry standard, balanced quality/speed

---

## TÃ i liá»‡u liÃªn quan
- [Text Chunking](./02_text_chunking.md)
- [FAISS Vector Search](./04_faiss_vector_search.md)
