# TECHNICAL DESIGN DOCUMENT (TDD)
**Project Name:** AI Legal Assistant (RAG System) - MVP Version
**Version:** 1.0.0
**Status:** Approved for Development

---

## 1. Tá»”NG QUAN KIáº¾N TRÃšC (SYSTEM ARCHITECTURE)

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ theo mÃ´ hÃ¬nh **Modular Monolith**, chia tÃ¡ch rÃµ rÃ ng giá»¯a hai luá»“ng xá»­ lÃ½ chÃ­nh Ä‘á»ƒ Ä‘áº£m báº£o kháº£ nÄƒng má»Ÿ rá»™ng (Scalability) vÃ  báº£o trÃ¬ (Maintainability).

### 1.1. High-Level Data Flow
1.  **Offline Pipeline (Data Ingestion):**
    * Input: VÄƒn báº£n phÃ¡p luáº­t (PDF, Docx).
    * Process: Load -> Clean -> Chunking -> Embedding.
    * Output: Vector Index (lÆ°u trá»¯ trÃªn Ä‘Ä©a cá»©ng/memory).
2.  **Online Pipeline (RAG Inference):**
    * Input: User Query.
    * Process: Query Embedding -> Semantic Search (Vector DB) -> Context Construction -> LLM Generation.
    * Output: Natural Language Answer + Citation.

### 1.2. Tech Stack (Hard Constraints)
* **Language:** Python 3.10+
* **Orchestration Framework:** LangChain (Core framework).
* **Vector Database:** FAISS (Local) hoáº·c ChromaDB (Æ°u tiÃªn FAISS cho MVP vÃ¬ dá»… triá»ƒn khai).
* **Embedding Model:** `bkai-foundation-models/vietnamese-bi-encoder` (HuggingFace).
* **LLM Provider:** Google Gemini API (`gemini-pro`).
* **Frontend:** Streamlit.

---

## 2. Cáº¤U TRÃšC THÆ¯ Má»¤C (DIRECTORY STRUCTURE)

Ká»¹ sÆ° cáº§n tuÃ¢n thá»§ chÃ­nh xÃ¡c cáº¥u trÃºc nÃ y Ä‘á»ƒ Ä‘áº£m báº£o Clean Architecture.

```text
project_root/
â”œâ”€â”€ .env                    # Chá»©a API KEYS (Google API, LangSmith...)
â”œâ”€â”€ requirements.txt        # Danh sÃ¡ch thÆ° viá»‡n
â”œâ”€â”€ README.md               # HÆ°á»›ng dáº«n cháº¡y
â”œâ”€â”€ data/                   # Táº§ng lÆ°u trá»¯ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                # Chá»©a file PDF/Docx gá»‘c do ngÆ°á»i dÃ¹ng upload
â”‚   â””â”€â”€ vector_store/       # Chá»©a index file cá»§a FAISS/Chroma (Ä‘Æ°á»£c sinh ra tá»± Ä‘á»™ng)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # Quáº£n lÃ½ cáº¥u hÃ¬nh táº­p trung (Singleton)
â”‚   â”œâ”€â”€ ingestion/          # MODULE 1: Xá»­ lÃ½ dá»¯ liá»‡u Ä‘áº§u vÃ o
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py       # Xá»­ lÃ½ Ä‘á»c file
â”‚   â”‚   â”œâ”€â”€ splitter.py     # Xá»­ lÃ½ cáº¯t vÄƒn báº£n
â”‚   â”‚   â””â”€â”€ indexer.py      # Xá»­ lÃ½ Embedding vÃ  lÆ°u vÃ o Vector DB
â”‚   â”œâ”€â”€ rag_engine/         # MODULE 2: Xá»­ lÃ½ logic RAG
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ retriever.py    # Logic tÃ¬m kiáº¿m vector
â”‚   â”‚   â”œâ”€â”€ generator.py    # Logic gá»i LLM vÃ  táº¡o cÃ¢u tráº£ lá»i
â”‚   â”‚   â””â”€â”€ prompts.py      # Quáº£n lÃ½ Prompt Templates táº­p trung
â”‚   â””â”€â”€ utils/              # CÃ¡c hÃ m tiá»‡n Ã­ch chung
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py       # Cáº¥u hÃ¬nh logging há»‡ thá»‘ng
â””â”€â”€ app.py                  # Entry point cho Streamlit UI
```

---

## 3. THIáº¾T Káº¾ CHI TIáº¾T MODULE (DETAILED COMPONENT DESIGN)

### 3.1. Module Cáº¥u HÃ¬nh (`src/config.py`)

**Má»¥c tiÃªu:** TrÃ¡nh hard-code, quáº£n lÃ½ biáº¿n mÃ´i trÆ°á»ng táº¡i má»™t nÆ¡i duy nháº¥t.

-   **Class:** `AppConfig`
    
    -   **Attributes:**
        
        -   `GOOGLE_API_KEY`: String
            
        -   `EMBEDDING_MODEL_NAME`: String (Default: "bkai-foundation-models/vietnamese-bi-encoder")
            
        -   `VECTOR_DB_PATH`: Path (ÄÆ°á»ng dáº«n lÆ°u file index)
            
        -   `CHUNK_SIZE`: Integer (Default: 1000)
            
        -   `CHUNK_OVERLAP`: Integer (Default: 200)
            
    -   **Behavior:** Tá»± Ä‘á»™ng load tá»« file `.env` khi khá»Ÿi táº¡o.
        

### 3.2. Module Ingestion (`src/ingestion`)

**Má»¥c tiÃªu:** Chuyá»ƒn Ä‘á»•i tÃ i liá»‡u thÃ´ thÃ nh Vector Database. Module nÃ y cháº¡y Ä‘á»™c láº­p (batch processing).

#### Component: `DocumentLoader` (`loader.py`)

-   **Function:** `load_documents(directory_path: str) -> List[Document]`
    
    -   **Logic:**
        
        1.  Duyá»‡t qua thÆ° má»¥c `data/raw`.
            
        2.  PhÃ¡t hiá»‡n Ä‘á»‹nh dáº¡ng file (PDF hoáº·c Docx).
            
        3.  Sá»­ dá»¥ng `PyPDFLoader` (cho PDF) hoáº·c `Docx2txtLoader` (cho Word) cá»§a LangChain.
            
        4.  Tráº£ vá» danh sÃ¡ch Ä‘á»‘i tÆ°á»£ng `Document` chá»©a ná»™i dung text vÃ  metadata (sá»‘ trang, tÃªn file).
            

#### Component: `TextSplitter` (`splitter.py`)

-   **Function:** `split_documents(documents: List[Document]) -> List[Document]`
    
    -   **Logic:**
        
        1.  Khá»Ÿi táº¡o `RecursiveCharacterTextSplitter` vá»›i cáº¥u hÃ¬nh tá»« `AppConfig`.
            
        2.  Thá»±c hiá»‡n split.
            
        3.  **Quan trá»ng:** Äáº£m báº£o metadata cá»§a document gá»‘c Ä‘Æ°á»£c sao chÃ©p sang tá»«ng chunk con.
            

#### Component: `VectorIndexer` (`indexer.py`)

-   **Function:** `build_index(chunks: List[Document]) -> None`
    
    -   **Logic:**
        
        1.  Khá»Ÿi táº¡o `HuggingFaceEmbeddings` vá»›i model tá»« config.
            
        2.  Khá»Ÿi táº¡o Vector Store (FAISS) tá»« cÃ¡c chunks vÃ  model embedding.
            
        3.  LÆ°u (Save) index xuá»‘ng Ä‘Ä©a cá»©ng táº¡i Ä‘Æ°á»ng dáº«n `VECTOR_DB_PATH`.
            

### 3.3. Module RAG Engine (`src/rag_engine`)

**Má»¥c tiÃªu:** Xá»­ lÃ½ truy váº¥n thá»i gian thá»±c.

#### Component: `VectorRetriever` (`retriever.py`)

-   **Class:** `SemanticRetriever`
    
    -   **Method:** `__init__(db_path, embedding_model_name)`
        
        -   Load FAISS index tá»« Ä‘Ä©a cá»©ng (trÃ¡nh viá»‡c build láº¡i má»—i láº§n cháº¡y).
            
    -   **Method:** `get_relevant_docs(query: str, k: int = 4) -> List[Document]`
        
        -   Thá»±c hiá»‡n similarity search.
            
        -   Tráº£ vá» top `k` Ä‘oáº¡n vÄƒn báº£n liÃªn quan nháº¥t.
            

#### Component: `PromptManager` (`prompts.py`)

-   **Variable:** `QA_PROMPT_TEMPLATE`
    
    -   **Content:** Template chuá»—i chá»©a placeholder `{context}` vÃ  `{question}`.
        
    -   **YÃªu cáº§u:** Pháº£i cÃ³ chá»‰ dáº«n rÃµ rÃ ng cho LLM: "Chá»‰ tráº£ lá»i dá»±a trÃªn context", "TrÃ­ch dáº«n nguá»“n náº¿u cÃ³ thá»ƒ", "Náº¿u khÃ´ng biáº¿t thÃ¬ nÃ³i khÃ´ng biáº¿t".
        

#### Component: `RAGGenerator` (`generator.py`)

-   **Class:** `RAGChain`
    
    -   **Attributes:** `llm`, `retriever`, `prompt`.
        
    -   **Method:** `generate_answer(query: str) -> Dict`
        
        -   **Input:** CÃ¢u há»i ngÆ°á»i dÃ¹ng.
            
        -   **Steps:**
            
            1.  Gá»i `retriever.get_relevant_docs(query)`.
                
            2.  Format prompt vá»›i context láº¥y Ä‘Æ°á»£c.
                
            3.  Gá»­i request tá»›i Gemini API (`ChatGoogleGenerativeAI`).
                
        -   **Output:** Dictionary chá»©a:
            
            -   `answer`: CÃ¢u tráº£ lá»i tá»« LLM.
                
            -   `source_documents`: List cÃ¡c documents Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ tham kháº£o (dÃ¹ng cho tÃ­nh nÄƒng trÃ­ch dáº«n).
                

### 3.4. Application Entry Point (`app.py`)

**Má»¥c tiÃªu:** Giao diá»‡n ngÆ°á»i dÃ¹ng (Streamlit).

-   **Logic Flow:**
    
    1.  **Initialize:** Khi app khá»Ÿi Ä‘á»™ng, gá»i `RAGChain` (Load model vÃ  Vector DB má»™t láº§n duy nháº¥t vÃ o `st.session_state` Ä‘á»ƒ tá»‘i Æ°u hiá»‡u nÄƒng).
        
    2.  **Sidebar:** NÃºt "Re-index Data" -> Gá»i `src.ingestion.indexer` Ä‘á»ƒ build láº¡i dá»¯ liá»‡u náº¿u ngÆ°á»i dÃ¹ng upload file má»›i vÃ o `data/raw`.
        
    3.  **Main Chat Interface:**
        
        -   Input box cho ngÆ°á»i dÃ¹ng.
            
        -   Khi Enter -> Gá»i `chain.generate_answer`.
            
        -   Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i.
            
        -   **UI Requirement:** BÃªn dÆ°á»›i cÃ¢u tráº£ lá»i, hiá»ƒn thá»‹ block "Nguá»“n tham kháº£o" (Expandable), liá»‡t kÃª tÃªn file vÃ  ná»™i dung trÃ­ch dáº«n tá»« `source_documents`.
            

* * *

## 4. QUY TRÃŒNH PHÃT TRIá»‚N (DEVELOPMENT WORKFLOW)

Ká»¹ sÆ° thá»±c hiá»‡n theo thá»© tá»± sau Ä‘á»ƒ Ä‘áº£m báº£o kiá»ƒm thá»­ tá»«ng pháº§n:

1.  **Setup Environment:** Táº¡o venv, cÃ i thÆ° viá»‡n (`langchain`, `faiss-cpu`, `google-generativeai`, `streamlit`, `pypdf`, `sentence-transformers`).
    
2.  **Implement Ingestion Layer:** Viáº¿t code cho `src/ingestion`. Cháº¡y thá»­ script Ä‘á»ƒ Ä‘áº£m báº£o file PDF Ä‘Æ°á»£c biáº¿n thÃ nh folder `vector_store` thÃ nh cÃ´ng.
    
3.  **Implement RAG Engine:** Viáº¿t code cho `src/rag_engine`. Viáº¿t script test nhá»: hard-code má»™t cÃ¢u há»i, in ra cÃ¢u tráº£ lá»i vÃ  nguá»“n trÃªn terminal.
    
4.  **Implement UI:** Viáº¿t `app.py` Ä‘á»ƒ káº¿t ná»‘i giao diá»‡n vá»›i RAG Engine.
    

## 5. LÆ¯U Ã Ká»¸ THUáº¬T QUAN TRá»ŒNG (ENGINEERING NOTES)

-   **Abstraction:** KhÃ´ng gá»i trá»±c tiáº¿p `google.generativeai` trong `app.py`. Má»i logic gá»i API pháº£i náº±m trong `src/rag_engine/generator.py`. Äiá»u nÃ y giÃºp sau nÃ y Ä‘á»•i sang Model khÃ¡c dá»… dÃ ng.

-   **Error Handling:** Pháº£i xá»­ lÃ½ trÆ°á»ng há»£p Vector DB chÆ°a tá»“n táº¡i (láº§n Ä‘áº§u cháº¡y). Náº¿u chÆ°a cÃ³, hiá»ƒn thá»‹ cáº£nh bÃ¡o trÃªn UI yÃªu cáº§u ngÆ°á»i dÃ¹ng báº¥m "Build Index".

-   **Citation Key:** Khi chunking, Ä‘áº£m báº£o `metadata` cá»§a chunk chá»©a `source` (tÃªn file) vÃ  `page` (trang sá»‘). ÄÃ¢y lÃ  chÃ¬a khÃ³a Ä‘á»ƒ tÃ­nh nÄƒng trÃ­ch dáº«n hoáº¡t Ä‘á»™ng.

---

## 6. LOW-LEVEL DESIGN SUPPLEMENT (CHI TIáº¾T Bá»” SUNG)

Pháº§n nÃ y bá»• sung cÃ¡c chi tiáº¿t ká»¹ thuáº­t cáº§n thiáº¿t Ä‘á»ƒ triá»ƒn khai code mÃ  khÃ´ng cáº§n suy luáº­n.

---

### 6.1. Error Handling Specification

#### 6.1.1. API Error Handling (`src/rag_engine/generator.py`)

| Error Type | HTTP Code | Behavior | Retry Strategy |
|------------|-----------|----------|----------------|
| Rate Limit | `429` | Log warning, retry vá»›i exponential backoff | Max 3 retries, delay: 1s â†’ 2s â†’ 4s |
| Server Error | `500-503` | Log error, retry | Max 2 retries, delay: 2s |
| Auth Error | `401/403` | Log critical, raise exception | No retry, notify user |
| Timeout | N/A | Log warning, retry | Max 2 retries, timeout: 30s |
| Invalid Response | N/A | Log error, return fallback message | No retry |

**Fallback Message:**
```python
FALLBACK_RESPONSE = {
    "answer": "Xin lá»—i, há»‡ thá»‘ng Ä‘ang gáº·p sá»± cá»‘. Vui lÃ²ng thá»­ láº¡i sau.",
    "source_documents": [],
    "error": True
}
```

#### 6.1.2. File Processing Errors (`src/ingestion/loader.py`)

| Error Type | Behavior | User Notification |
|------------|----------|-------------------|
| Corrupt PDF | Skip file, log error with filename | Add to `failed_files` list |
| Password-protected PDF | Skip file, log warning | Add to `failed_files` list |
| Unsupported format | Skip file, log warning | Add to `failed_files` list |
| Empty file | Skip file, log info | Add to `failed_files` list |
| Encoding error | Try UTF-8 â†’ Latin-1 â†’ Skip | Add to `failed_files` if all fail |

**Return Type:**
```python
@dataclass
class LoadResult:
    documents: List[Document]
    failed_files: List[Dict[str, str]]  # {"file": "name.pdf", "reason": "corrupt"}
```

#### 6.1.3. Embedding Model Errors (`src/ingestion/indexer.py`)

| Error Type | Behavior |
|------------|----------|
| Model download timeout | Timeout after 300s, raise exception with clear message |
| CUDA out of memory | Fallback to CPU, log warning |
| Invalid chunk (empty text) | Skip chunk, log warning |

---

### 6.2. Validation Logic

#### 6.2.1. File Upload Validation

```python
# src/utils/validators.py

class FileValidator:
    MAX_FILE_SIZE_MB: int = 50  # Maximum 50MB per file
    MAX_TOTAL_SIZE_MB: int = 200  # Maximum 200MB total in data/raw
    ALLOWED_EXTENSIONS: Set[str] = {".pdf", ".docx", ".doc"}
    ALLOWED_MIME_TYPES: Set[str] = {
        "application/pdf",
        "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        "application/msword"
    }
```

| Validation | Action on Failure |
|------------|-------------------|
| File size > 50MB | Reject with message: "File quÃ¡ lá»›n. Giá»›i háº¡n: 50MB" |
| Invalid extension | Reject with message: "Äá»‹nh dáº¡ng khÃ´ng há»— trá»£. Chá»‰ cháº¥p nháº­n: PDF, DOCX" |
| MIME type mismatch | Reject with message: "File khÃ´ng há»£p lá»‡" |
| Total size exceeded | Reject with message: "ÄÃ£ vÆ°á»£t quÃ¡ dung lÆ°á»£ng lÆ°u trá»¯ cho phÃ©p" |

#### 6.2.2. Duplicate Document Handling

**Strategy:** `REPLACE` - Náº¿u file cÃ¹ng tÃªn Ä‘Ã£ tá»“n táº¡i, thay tháº¿ file cÅ©.

```python
# src/ingestion/indexer.py

class DuplicateStrategy(Enum):
    REPLACE = "replace"  # Default: Thay tháº¿ document cÅ©
    SKIP = "skip"        # Bá» qua náº¿u Ä‘Ã£ tá»“n táº¡i
    APPEND = "append"    # ThÃªm suffix _v2, _v3...
```

#### 6.2.3. Query Validation

```python
# src/rag_engine/retriever.py

class QueryValidator:
    MIN_QUERY_LENGTH: int = 2
    MAX_QUERY_LENGTH: int = 1000
    
    @staticmethod
    def validate(query: str) -> Tuple[bool, str]:
        if len(query.strip()) < MIN_QUERY_LENGTH:
            return False, "CÃ¢u há»i quÃ¡ ngáº¯n"
        if len(query) > MAX_QUERY_LENGTH:
            return False, "CÃ¢u há»i quÃ¡ dÃ i (tá»‘i Ä‘a 1000 kÃ½ tá»±)"
        return True, ""
```

---

### 6.3. Data Flow Details

#### 6.3.1. Metadata Schema

```python
# src/models/document.py

@dataclass
class ChunkMetadata:
    source: str          # TÃªn file gá»‘c, e.g., "luat_dan_su_2015.pdf"
    page: int            # Sá»‘ trang (1-indexed), 0 náº¿u khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c
    chunk_id: str        # UUID v4, e.g., "a1b2c3d4-..."
    chunk_index: int     # Thá»© tá»± chunk trong document (0-indexed)
    total_chunks: int    # Tá»•ng sá»‘ chunks cá»§a document
    created_at: str      # ISO 8601 timestamp, e.g., "2024-01-15T10:30:00Z"
    file_hash: str       # MD5 hash cá»§a file gá»‘c (Ä‘á»ƒ detect duplicates)
```

**Example:**
```json
{
    "source": "luat_dan_su_2015.pdf",
    "page": 15,
    "chunk_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
    "chunk_index": 42,
    "total_chunks": 150,
    "created_at": "2024-01-15T10:30:00Z",
    "file_hash": "d41d8cd98f00b204e9800998ecf8427e"
}
```

#### 6.3.2. Chunk ID Generation

```python
import uuid

def generate_chunk_id() -> str:
    """Generate unique chunk ID using UUID v4."""
    return str(uuid.uuid4())
```

#### 6.3.3. Context Window Management

```python
# src/rag_engine/retriever.py

class ContextManager:
    MAX_CONTEXT_TOKENS: int = 8000  # Gemini context limit buffer
    CHARS_PER_TOKEN: float = 4.0    # Approximate for Vietnamese
    
    @staticmethod
    def truncate_context(chunks: List[Document], max_tokens: int = MAX_CONTEXT_TOKENS) -> List[Document]:
        """
        Truncate chunks to fit within context window.
        Strategy: Keep first N chunks that fit, prioritize by relevance score.
        """
        result = []
        current_chars = 0
        max_chars = int(max_tokens * CHARS_PER_TOKEN)
        
        for chunk in chunks:
            chunk_chars = len(chunk.page_content)
            if current_chars + chunk_chars <= max_chars:
                result.append(chunk)
                current_chars += chunk_chars
            else:
                # Truncate last chunk if partially fits
                remaining = max_chars - current_chars
                if remaining > 200:  # Minimum useful content
                    truncated = Document(
                        page_content=chunk.page_content[:remaining] + "...",
                        metadata=chunk.metadata
                    )
                    result.append(truncated)
                break
        
        return result
```

---

### 6.4. State Management

#### 6.4.1. Re-indexing Behavior

**Strategy:** `FULL_REPLACE` - XÃ³a index cÅ©, build láº¡i hoÃ n toÃ n.

```python
# src/ingestion/indexer.py

class IndexingMode(Enum):
    FULL_REPLACE = "full_replace"  # Default: XÃ³a index cÅ©, build má»›i
    INCREMENTAL = "incremental"    # Future: Chá»‰ thÃªm documents má»›i

def build_index(chunks: List[Document], mode: IndexingMode = IndexingMode.FULL_REPLACE) -> None:
    if mode == IndexingMode.FULL_REPLACE:
        # Delete existing index
        if os.path.exists(VECTOR_DB_PATH):
            shutil.rmtree(VECTOR_DB_PATH)
    # Build new index...
```

#### 6.4.2. Concurrent Access Protection

```python
# src/utils/lock.py

import filelock

INDEX_LOCK_PATH = "data/vector_store/.index.lock"

def with_index_lock(timeout: int = 60):
    """Decorator to prevent concurrent index modifications."""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            lock = filelock.FileLock(INDEX_LOCK_PATH, timeout=timeout)
            try:
                with lock:
                    return func(*args, **kwargs)
            except filelock.Timeout:
                raise RuntimeError("Index Ä‘ang Ä‘Æ°á»£c cáº­p nháº­t bá»Ÿi tiáº¿n trÃ¬nh khÃ¡c. Vui lÃ²ng thá»­ láº¡i sau.")
        return wrapper
    return decorator
```

#### 6.4.3. Session & Chat History

**Strategy:** `SESSION_ONLY` - Chat history chá»‰ tá»“n táº¡i trong session hiá»‡n táº¡i.

```python
# app.py

# Session state structure
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # List[Dict[str, str]]

# Chat history item format:
# {"role": "user" | "assistant", "content": "...", "sources": [...]}

# Maximum history length
MAX_CHAT_HISTORY = 50
```

---

### 6.5. Performance Specifications

#### 6.5.1. Timeout Configuration

```python
# src/config.py

class TimeoutConfig:
    LLM_REQUEST_TIMEOUT: int = 30        # seconds
    EMBEDDING_REQUEST_TIMEOUT: int = 60  # seconds
    VECTOR_SEARCH_TIMEOUT: int = 10      # seconds
    FILE_PROCESSING_TIMEOUT: int = 120   # seconds per file
```

#### 6.5.2. Batch Processing

```python
# src/ingestion/indexer.py

class BatchConfig:
    EMBEDDING_BATCH_SIZE: int = 32   # Chunks per embedding batch
    INDEX_BATCH_SIZE: int = 500      # Chunks per index write
    MAX_WORKERS: int = 4             # Parallel file processing
```

#### 6.5.3. FAISS Configuration

```python
# src/config.py

class FAISSConfig:
    INDEX_TYPE: str = "Flat"              # "Flat" for MVP, "IVF" for large scale
    USE_GPU: bool = False                 # CPU only for MVP
    NORMALIZE_VECTORS: bool = True        # L2 normalization
    SAVE_FORMAT: str = "local"            # "local" disk storage
```

---

### 6.6. Security Considerations

#### 6.6.1. Input Sanitization

```python
# src/utils/sanitizer.py

import re

class QuerySanitizer:
    # Patterns that might indicate prompt injection
    DANGEROUS_PATTERNS = [
        r"ignore\s+(previous|above|all)\s+instructions",
        r"forget\s+(everything|all)",
        r"you\s+are\s+now",
        r"act\s+as\s+a",
        r"system\s*:\s*",
    ]
    
    @staticmethod
    def sanitize(query: str) -> str:
        """Remove potentially dangerous patterns from user query."""
        sanitized = query
        for pattern in DANGEROUS_PATTERNS:
            sanitized = re.sub(pattern, "", sanitized, flags=re.IGNORECASE)
        return sanitized.strip()
    
    @staticmethod
    def is_suspicious(query: str) -> bool:
        """Check if query contains suspicious patterns."""
        for pattern in DANGEROUS_PATTERNS:
            if re.search(pattern, query, re.IGNORECASE):
                return True
        return False
```

#### 6.6.2. File Security

```python
# src/utils/validators.py

import magic  # python-magic library

class FileSecurityValidator:
    @staticmethod
    def validate_mime_type(file_path: str) -> bool:
        """Verify file MIME type matches extension."""
        mime = magic.Magic(mime=True)
        detected_type = mime.from_file(file_path)
        
        extension = Path(file_path).suffix.lower()
        expected_types = {
            ".pdf": "application/pdf",
            ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            ".doc": "application/msword"
        }
        
        return detected_type == expected_types.get(extension)
```

#### 6.6.3. Environment Security

```text
# .gitignore (REQUIRED)

.env
.env.local
.env.*.local
data/vector_store/
*.pyc
__pycache__/
.pytest_cache/
```

---

### 6.7. Detailed Prompt Template

```python
# src/rag_engine/prompts.py

QA_SYSTEM_PROMPT = """Báº¡n lÃ  trá»£ lÃ½ phÃ¡p luáº­t AI chuyÃªn vá» luáº­t Viá»‡t Nam. 
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tráº£ lá»i cÃ¢u há»i Dá»°A TRÃŠN cÃ¡c tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p.

NGUYÃŠN Táº®C Báº®T BUá»˜C:
1. CHá»ˆ tráº£ lá»i dá»±a trÃªn thÃ´ng tin trong pháº§n [TÃ€I LIá»†U THAM KHáº¢O]
2. Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan, tráº£ lá»i: "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» váº¥n Ä‘á» nÃ y trong cÃ¡c tÃ i liá»‡u hiá»‡n cÃ³."
3. LUÃ”N trÃ­ch dáº«n nguá»“n theo format: [Nguá»“n: tÃªn_file, Trang: sá»‘_trang]
4. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
5. Giá»¯ cÃ¢u tráº£ lá»i sÃºc tÃ­ch, rÃµ rÃ ng
6. KHÃ”NG bá»‹a Ä‘áº·t thÃ´ng tin khÃ´ng cÃ³ trong tÃ i liá»‡u"""

QA_USER_PROMPT_TEMPLATE = """[TÃ€I LIá»†U THAM KHáº¢O]
{context}

[CÃ‚U Há»ŽI]
{question}

[TRáº¢ Lá»œI]
HÃ£y tráº£ lá»i cÃ¢u há»i trÃªn dá»±a trÃªn tÃ i liá»‡u tham kháº£o. Nhá»› trÃ­ch dáº«n nguá»“n."""

# Citation format example in response:
# "Theo Äiá»u 15 Luáº­t DÃ¢n sá»± 2015, [Nguá»“n: luat_dan_su_2015.pdf, Trang: 12]..."
```

#### Context Formatting

```python
# src/rag_engine/prompts.py

def format_context(documents: List[Document]) -> str:
    """Format retrieved documents into context string."""
    context_parts = []
    
    for i, doc in enumerate(documents, 1):
        source = doc.metadata.get("source", "Unknown")
        page = doc.metadata.get("page", "N/A")
        content = doc.page_content.strip()
        
        context_parts.append(
            f"--- TÃ i liá»‡u {i} ---\n"
            f"Nguá»“n: {source} | Trang: {page}\n"
            f"Ná»™i dung:\n{content}\n"
        )
    
    return "\n".join(context_parts)
```

---

### 6.8. Constants & Enums (`src/constants.py`)

```python
from enum import Enum

class ResponseStatus(Enum):
    SUCCESS = "success"
    ERROR = "error"
    NO_CONTEXT = "no_context"
    RATE_LIMITED = "rate_limited"

class IndexStatus(Enum):
    NOT_INITIALIZED = "not_initialized"
    BUILDING = "building"
    READY = "ready"
    ERROR = "error"

# UI Messages
UI_MESSAGES = {
    "NO_INDEX": "âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u. Vui lÃ²ng upload file vÃ  báº¥m 'Build Index'.",
    "INDEXING": "ðŸ”„ Äang xá»­ lÃ½ dá»¯ liá»‡u...",
    "INDEX_SUCCESS": "âœ… Xá»­ lÃ½ dá»¯ liá»‡u thÃ nh cÃ´ng!",
    "INDEX_ERROR": "âŒ Lá»—i xá»­ lÃ½ dá»¯ liá»‡u: {error}",
    "QUERY_ERROR": "âŒ KhÃ´ng thá»ƒ xá»­ lÃ½ cÃ¢u há»i. Vui lÃ²ng thá»­ láº¡i.",
    "EMPTY_QUERY": "âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i.",
}
```

---

## 7. DEPENDENCIES (`requirements.txt`)

```text
# Core
langchain>=0.1.0
langchain-google-genai>=0.0.6
langchain-community>=0.0.10

# Vector Store
faiss-cpu>=1.7.4

# Embeddings
sentence-transformers>=2.2.2

# Document Processing
pypdf>=3.17.0
python-docx>=1.1.0
docx2txt>=0.8

# Web UI
streamlit>=1.29.0

# Utilities
python-dotenv>=1.0.0
filelock>=3.13.0
python-magic>=0.4.27

# Development
pytest>=7.4.0
black>=23.0.0
mypy>=1.7.0
```

---

## 8. APPENDIX: TYPE HINTS SUMMARY

```python
# src/types.py

from typing import TypedDict, List, Optional

class ChunkMetadataDict(TypedDict):
    source: str
    page: int
    chunk_id: str
    chunk_index: int
    total_chunks: int
    created_at: str
    file_hash: str

class RAGResponse(TypedDict):
    answer: str
    source_documents: List[dict]
    status: str  # ResponseStatus value
    error: Optional[str]

class LoadResultDict(TypedDict):
    documents: List[dict]
    failed_files: List[dict]
    total_processed: int
    total_failed: int
```


