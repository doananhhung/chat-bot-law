---
---

<LayoutSection title="RAG Engine & LLM Integration">

**T·ª´ Search Results ‚Üí C√¢u Tr·∫£ L·ªùi Th√¥ng Minh**

üë§ Ph√∫c

</LayoutSection>

---

<LayoutComparison title="Keyword vs Semantic Search" leftTitle="Keyword Search" rightTitle="Semantic Search">

<template #left>

### Exact Word Matching

```
Query: "ngh·ªâ ƒë·∫ª ƒë∆∞·ª£c m·∫•y th√°ng?"

‚ùå Kh√¥ng match "thai s·∫£n"
‚ùå Miss relevant documents
```

- Ch·ªâ t√¨m **exact words**
- Miss: "ngh·ªâ ƒë·∫ª", "maternity"

</template>

<template #right>

### Meaning-based Matching

```
Query: "ngh·ªâ ƒë·∫ª ƒë∆∞·ª£c m·∫•y th√°ng?"

‚úÖ Match "ngh·ªâ thai s·∫£n"
‚úÖ Match "sinh con"
```

- Hi·ªÉu **√Ω nghƒ©a/kh√°i ni·ªám**
- Catch t·∫•t c·∫£ related terms

</template>

</LayoutComparison>

---

<LayoutTitleContent title="SemanticRetriever Class">

```python
# src/rag_engine/retriever.py
class SemanticRetriever:
    def __init__(self):
        self.embeddings = HuggingFaceEmbeddings(...)  # vietnamese-bi-encoder
        self.vector_store = FAISS.load_local(...)     # FAISS index
    
    def get_relevant_docs(self, query: str, k: int = 10):
        """Retrieve top-k relevant documents."""
        docs = self.vector_store.similarity_search(query, k=k)
        return docs
```

| Parameter | Gi√° tr·ªã | √ù nghƒ©a |
|-----------|---------|---------|
| **k** | 10 | L·∫•y top 10 documents li√™n quan nh·∫•t |
| **Search** | similarity_search | D·ª±a tr√™n cosine similarity |

</LayoutTitleContent>

---

<LayoutComparison title="Intent Routing" leftTitle="Without Router" rightTitle="With Router">

<template #left>

### Bad UX

```
User: "Xin ch√†o!"

System: [searches legal database]

System: "T√¥i kh√¥ng t√¨m th·∫•y 
t√†i li·ªáu v·ªÅ 'xin ch√†o'..."
```

‚ùå C·ªë search m·ªçi th·ª©

</template>

<template #right>

### Good UX

```
User: "Xin ch√†o!"

Router: ‚Üí GENERAL

System: "Xin ch√†o! T√¥i l√† 
tr·ª£ l√Ω ph√°p l√Ω AI..."
```

‚úÖ Ph·∫£n h·ªìi th√¥ng minh

</template>

</LayoutComparison>

---

<LayoutTwoCol title="Intent Router Implementation">

<template #left>

### Router Prompt

```python
ROUTER_TEMPLATE = """
Ph√¢n lo·∫°i c√¢u h·ªèi:
1. "LEGAL": Lu·∫≠t ph√°p, quy ƒë·ªãnh
2. "GENERAL": Ch√†o h·ªèi, x√£ giao

CH·ªà tr·∫£ v·ªÅ: "LEGAL" ho·∫∑c "GENERAL"

C√¢u h·ªèi: {question}
"""
```

</template>

<template #right>

### V√≠ d·ª• ph√¢n lo·∫°i

| Query | Intent |
|-------|--------|
| "Thai s·∫£n ngh·ªâ m·∫•y th√°ng?" | **LEGAL** |
| "Xin ch√†o!" | **GENERAL** |
| "ƒêi·ªÅu 139 n√≥i g√¨?" | **LEGAL** |
| "1 + 1 = ?" | **GENERAL** |

**LEGAL** ‚Üí RAG Pipeline  
**GENERAL** ‚Üí Direct Response

</template>

</LayoutTwoCol>

---

<LayoutDiagram title="Query Rewriting">

```mermaid
flowchart LR
    subgraph Solution["GI·∫¢I PH√ÅP"]
        E["Original: 'C√≤n nam th√¨ sao?'"]
        F["üß† Query Rewriting"]
        G["Rewritten: 'Lao ƒë·ªông nam c√≥ ƒë∆∞·ª£c ngh·ªâ thai s·∫£n kh√¥ng?'"]
        H["‚úÖ C√¢u h·ªèi r√µ r√†ng!"]
    end
    
    subgraph Problem["V·∫§N ƒê·ªÄ"]
        A["User: 'Thai s·∫£n ngh·ªâ m·∫•y th√°ng?'"]
        B["AI: 'Lao ƒë·ªông n·ªØ ƒë∆∞·ª£c ngh·ªâ 6 th√°ng...'"]
        C["User: 'C√≤n nam th√¨ sao?'"]
        D["‚ùå C√¢u h·ªèi thi·∫øu context!"]
    end
    
    A --> B --> C --> D
    E --> F --> G --> H
```

</LayoutDiagram>

---

<LayoutTitleContent title="System Prompt - AI Definition">

```python
QA_SYSTEM_PROMPT = """
B·∫°n l√† C·ªë v·∫•n Ph√°p l√Ω AI c·∫•p cao, chuy√™n v·ªÅ Lu·∫≠t Lao ƒë·ªông Vi·ªát Nam.
Phong c√°ch: Chuy√™n nghi·ªáp, Kh√°ch quan, D·ª±a tr√™n b·∫±ng ch·ª©ng.

QUY TR√åNH T∆Ø DUY (Chain of Thought):
1. ƒê·ªçc k·ªπ c√¢u h·ªèi ƒë·ªÉ x√°c ƒë·ªãnh v·∫•n ƒë·ªÅ ph√°p l√Ω c·ªët l√µi
2. R√† so√°t [T√ÄI LI·ªÜU THAM KH·∫¢O] ƒë·ªÉ t√¨m ƒêi·ªÅu kho·∫£n li√™n quan
3. X√¢y d·ª±ng c√¢u tr·∫£ l·ªùi theo c·∫•u tr√∫c IRAC

NGUY√äN T·∫ÆC B·∫ÆT BU·ªòC:
1. TUY·ªÜT ƒê·ªêI KH√îNG B·ªäA ƒê·∫∂T (Hallucination)
2. CH·ªà s·ª≠ d·ª•ng th√¥ng tin t·ª´ Context
3. LU√îN tr√≠ch d·∫´n ngu·ªìn c·ª• th·ªÉ [Ngu·ªìn: file.pdf, Trang: X]
"""
```

</LayoutTitleContent>

---

<LayoutTwoCol title="IRAC Structure">

<template #left>

### Framework

| Component | Meaning |
|-----------|---------|
| **I**ssue | V·∫•n ƒë·ªÅ ph√°p l√Ω |
| **R**ule | ƒêi·ªÅu lu·∫≠t √°p d·ª•ng |
| **A**nalysis | Ph√¢n t√≠ch c·ª• th·ªÉ |
| **C**onclusion | K·∫øt lu·∫≠n ng·∫Øn g·ªçn |

</template>

<template #right>

### Example Response

```markdown
### 1. CƒÉn c·ª© ph√°p l√Ω
- ƒêi·ªÅu 139 BLLƒê 2019 
  [Ngu·ªìn: blld.pdf, Trang: 46]

### 2. Ph√¢n t√≠ch
Theo ƒêi·ªÅu 139, lao ƒë·ªông n·ªØ 
ƒë∆∞·ª£c ngh·ªâ thai s·∫£n t·ªïng c·ªông 
6 th√°ng...

### 3. K·∫øt lu·∫≠n
B·∫°n ƒë∆∞·ª£c ngh·ªâ **6 th√°ng**.
```

</template>

</LayoutTwoCol>

---

<LayoutTwoCol title="Context ">

<template #left>

### Query Rewriting

```python
# Input cho Rewriter LLM
{
    "chat_history": chat_history_str,
    "question": query
}
```

| Input | Source |  
|-------|---------|
| `chat_history_str` | role + content |


</template>

<template #right>

### RAG Generation

```python
# Input cho Generator LLM
{
    "context": format_context(docs),
    "question": standalone_query
}
```

| Input | Source |
|-------|--------|
| `context` | Vector Search |
| `question` | Rewriter output |

</template>

</LayoutTwoCol>

<!--
"Hai context quan tr·ªçng:

1. Query Rewriting: Ch·ªâ l·∫•y role v√† content t·ª´ database ƒë·ªÉ t·∫°o chat_history. Kh√¥ng c·∫ßn sources hay timestamp v√¨ LLM ch·ªâ c·∫ßn hi·ªÉu ng·ªØ c·∫£nh h·ªôi tho·∫°i.

2. RAG Generation: D√πng context t·ª´ Vector Search (c√°c ƒëo·∫°n vƒÉn b·∫£n ph√°p lu·∫≠t) v√† c√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c rewrite."
-->

---

<LayoutDiagram title="Multi-LLM Architecture">

```mermaid
flowchart TB
    subgraph Factory["LLM FACTORY PATTERN"]
        F["LLMFactory.create_llm(provider, model)"]
        G["if 'google' ‚Üí ChatGoogleGenerativeAI"]
        H["if 'groq' ‚Üí ChatGroq"]
        F --> G
        F --> H
    end
    
    subgraph Instances["LLM INSTANCES"]
        I1["ü§ñ Generator<br/>temp=0.3"]
        I2["üîÄ Router<br/>temp=0.0"]
        I3["‚úèÔ∏è Rewriter<br/>temp=0.0"]
    end
```

</LayoutDiagram>

---

<LayoutTwoCol title="Supported LLM Providers">

<template #left>

### Groq

| Thu·ªôc t√≠nh | Gi√° tr·ªã |
|------------|---------|
| Model | Kimi K2 |
| Speed | Ultra-fast (~300ms) |
| Free Tier | Generous |

```bash
LLM_PROVIDER=groq
LLM_MODEL_NAME=moonshotai/kimi-k2-instruct
```

</template>

<template #right>

### Google Gemini

| Thu·ªôc t√≠nh | Gi√° tr·ªã |
|------------|---------|
| Model | Gemini 2.5 Flash |
| Quality | High |
| Context | Large window |

```bash
LLM_PROVIDER=google
LLM_MODEL_NAME=gemini-2.5-flash-lite
```

</template>

</LayoutTwoCol>


