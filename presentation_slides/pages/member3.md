---
---

<LayoutSection title="RAG Engine & LLM Integration">

**Tá»« Search Results â†’ CÃ¢u Tráº£ Lá»i ThÃ´ng Minh**

ğŸ‘¤ Member 3

</LayoutSection>

---

<LayoutComparison title="Keyword vs Semantic Search" leftTitle="Keyword Search" rightTitle="Semantic Search">

<template #left>

### Exact Word Matching

```
Query: "nghá»‰ Ä‘áº» Ä‘Æ°á»£c máº¥y thÃ¡ng?"

âŒ KhÃ´ng match "thai sáº£n"
âŒ Miss relevant documents
```

- Chá»‰ tÃ¬m **exact words**
- Miss: "nghá»‰ Ä‘áº»", "maternity"

</template>

<template #right>

### Meaning-based Matching

```
Query: "nghá»‰ Ä‘áº» Ä‘Æ°á»£c máº¥y thÃ¡ng?"

âœ… Match "nghá»‰ thai sáº£n"
âœ… Match "sinh con"
```

- Hiá»ƒu **Ã½ nghÄ©a/khÃ¡i niá»‡m**
- Catch táº¥t cáº£ related terms

</template>

</LayoutComparison>

---

<LayoutTitleContent title="SemanticRetriever Class">

```python
# src/rag_engine/retriever.py
class SemanticRetriever:
    def __init__(self):
        self.embeddings = HuggingFaceEmbeddings(...)  # vietnamese-bi-encoder
        self.vector_store = FAISS.load_local(...)     # FAISS index
    
    def get_relevant_docs(self, query: str, k: int = 10):
        """Retrieve top-k relevant documents."""
        docs = self.vector_store.similarity_search(query, k=k)
        return docs
```

| Parameter | GiÃ¡ trá»‹ | Ã nghÄ©a |
|-----------|---------|---------|
| **k** | 10 | Láº¥y top 10 documents liÃªn quan nháº¥t |
| **Search** | similarity_search | Dá»±a trÃªn cosine similarity |

</LayoutTitleContent>

---

<LayoutComparison title="Intent Routing" leftTitle="Without Router" rightTitle="With Router">

<template #left>

### Bad UX

```
User: "Xin chÃ o!"

System: [searches legal database]

System: "TÃ´i khÃ´ng tÃ¬m tháº¥y 
tÃ i liá»‡u vá» 'xin chÃ o'..."
```

âŒ Cá»‘ search má»i thá»©

</template>

<template #right>

### Good UX

```
User: "Xin chÃ o!"

Router: â†’ GENERAL

System: "Xin chÃ o! TÃ´i lÃ  
trá»£ lÃ½ phÃ¡p lÃ½ AI..."
```

âœ… Pháº£n há»“i thÃ´ng minh

</template>

</LayoutComparison>

---

<LayoutTwoCol title="Intent Router Implementation">

<template #left>

### Router Prompt

```python
ROUTER_TEMPLATE = """
PhÃ¢n loáº¡i cÃ¢u há»i:
1. "LEGAL": Luáº­t phÃ¡p, quy Ä‘á»‹nh
2. "GENERAL": ChÃ o há»i, xÃ£ giao

CHá»ˆ tráº£ vá»: "LEGAL" hoáº·c "GENERAL"

CÃ¢u há»i: {question}
"""
```

</template>

<template #right>

### VÃ­ dá»¥ phÃ¢n loáº¡i

| Query | Intent |
|-------|--------|
| "Thai sáº£n nghá»‰ máº¥y thÃ¡ng?" | **LEGAL** |
| "Xin chÃ o!" | **GENERAL** |
| "Äiá»u 139 nÃ³i gÃ¬?" | **LEGAL** |
| "1 + 1 = ?" | **GENERAL** |

**LEGAL** â†’ RAG Pipeline  
**GENERAL** â†’ Direct Response

</template>

</LayoutTwoCol>

---

<LayoutDiagram title="Query Rewriting">

```mermaid
flowchart LR
    subgraph Solution["GIáº¢I PHÃP"]
        E["Original: 'CÃ²n nam thÃ¬ sao?'"]
        F["ğŸ§  Query Rewriting"]
        G["Rewritten: 'Lao Ä‘á»™ng nam cÃ³ Ä‘Æ°á»£c nghá»‰ thai sáº£n khÃ´ng?'"]
        H["âœ… CÃ¢u há»i rÃµ rÃ ng!"]
    end
    
    subgraph Problem["Váº¤N Äá»€"]
        A["User: 'Thai sáº£n nghá»‰ máº¥y thÃ¡ng?'"]
        B["AI: 'Lao Ä‘á»™ng ná»¯ Ä‘Æ°á»£c nghá»‰ 6 thÃ¡ng...'"]
        C["User: 'CÃ²n nam thÃ¬ sao?'"]
        D["âŒ CÃ¢u há»i thiáº¿u context!"]
    end
    
    A --> B --> C --> D
    E --> F --> G --> H
```

</LayoutDiagram>

---

<LayoutTitleContent title="What is Prompt Engineering?">

| KhÃ¡i niá»‡m | Giáº£i thÃ­ch |
|-----------|------------|
| **Prompt** | Input text gá»­i cho LLM |
| **Engineering** | Thiáº¿t káº¿ prompt Ä‘á»ƒ nháº­n output cháº¥t lÆ°á»£ng cao |

```
Same LLM, Different Prompts:

Prompt 1: "NÃ³i vá» thai sáº£n"
â†’ "Thai sáº£n lÃ  quÃ¡ trÃ¬nh mang thai vÃ  sinh con..."
   âŒ Generic, khÃ´ng focus phÃ¡p lÃ½

Prompt 2: "Báº¡n lÃ  Cá»‘ váº¥n PhÃ¡p lÃ½ AI. Dá»±a trÃªn tÃ i liá»‡u sau..."
â†’ "Theo Äiá»u 139 Bá»™ luáº­t Lao Ä‘á»™ng, lao Ä‘á»™ng ná»¯ Ä‘Æ°á»£c nghá»‰..."
   âœ… Professional, cÃ³ trÃ­ch dáº«n nguá»“n
```

</LayoutTitleContent>

---

<LayoutTitleContent title="System Prompt - AI Definition">

```python
QA_SYSTEM_PROMPT = """
Báº¡n lÃ  Cá»‘ váº¥n PhÃ¡p lÃ½ AI cáº¥p cao, chuyÃªn vá» Luáº­t Lao Ä‘á»™ng Viá»‡t Nam.
Phong cÃ¡ch: ChuyÃªn nghiá»‡p, KhÃ¡ch quan, Dá»±a trÃªn báº±ng chá»©ng.

QUY TRÃŒNH TÆ¯ DUY (Chain of Thought):
1. Äá»c ká»¹ cÃ¢u há»i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh váº¥n Ä‘á» phÃ¡p lÃ½ cá»‘t lÃµi
2. RÃ  soÃ¡t [TÃ€I LIá»†U THAM KHáº¢O] Ä‘á»ƒ tÃ¬m Äiá»u khoáº£n liÃªn quan
3. XÃ¢y dá»±ng cÃ¢u tráº£ lá»i theo cáº¥u trÃºc IRAC

NGUYÃŠN Táº®C Báº®T BUá»˜C:
1. TUYá»†T Äá»I KHÃ”NG Bá»ŠA Äáº¶T (Hallucination)
2. CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« Context
3. LUÃ”N trÃ­ch dáº«n nguá»“n cá»¥ thá»ƒ [Nguá»“n: file.pdf, Trang: X]
"""
```

</LayoutTitleContent>

---

<LayoutTwoCol title="IRAC Structure">

<template #left>

### Framework

| Component | Meaning |
|-----------|---------|
| **I**ssue | Váº¥n Ä‘á» phÃ¡p lÃ½ |
| **R**ule | Äiá»u luáº­t Ã¡p dá»¥ng |
| **A**nalysis | PhÃ¢n tÃ­ch cá»¥ thá»ƒ |
| **C**onclusion | Káº¿t luáº­n ngáº¯n gá»n |

</template>

<template #right>

### Example Response

```markdown
### 1. CÄƒn cá»© phÃ¡p lÃ½
- Äiá»u 139 BLLÄ 2019 
  [Nguá»“n: blld.pdf, Trang: 46]

### 2. PhÃ¢n tÃ­ch
Theo Äiá»u 139, lao Ä‘á»™ng ná»¯ 
Ä‘Æ°á»£c nghá»‰ thai sáº£n tá»•ng cá»™ng 
6 thÃ¡ng...

### 3. Káº¿t luáº­n
Báº¡n Ä‘Æ°á»£c nghá»‰ **6 thÃ¡ng**.
```

</template>

</LayoutTwoCol>

---

<LayoutDiagram title="Multi-LLM Architecture">

```mermaid
flowchart TB
    subgraph Factory["LLM FACTORY PATTERN"]
        F["LLMFactory.create_llm(provider, model)"]
        G["if 'google' â†’ ChatGoogleGenerativeAI"]
        H["if 'groq' â†’ ChatGroq"]
        F --> G
        F --> H
    end
    
    subgraph Instances["LLM INSTANCES"]
        I1["ğŸ¤– Generator<br/>temp=0.3"]
        I2["ğŸ”€ Router<br/>temp=0.0"]
        I3["âœï¸ Rewriter<br/>temp=0.0"]
    end
```

</LayoutDiagram>

---

<LayoutTwoCol title="Supported LLM Providers">

<template #left>

### Groq

| Thuá»™c tÃ­nh | GiÃ¡ trá»‹ |
|------------|---------|
| Model | Kimi K2 |
| Speed | Ultra-fast (~300ms) |
| Free Tier | Generous |

```bash
LLM_PROVIDER=groq
LLM_MODEL_NAME=moonshotai/kimi-k2-instruct
```

</template>

<template #right>

### Google Gemini

| Thuá»™c tÃ­nh | GiÃ¡ trá»‹ |
|------------|---------|
| Model | Gemini 2.5 Flash |
| Quality | High |
| Context | Large window |

```bash
LLM_PROVIDER=google
LLM_MODEL_NAME=gemini-2.5-flash-lite
```

</template>

</LayoutTwoCol>

---

<LayoutTitleContent title="RAG Engine Summary">

| Chá»§ Ä‘á» | Äiá»ƒm chÃ­nh |
|--------|------------|
| **Semantic Search** | Hiá»ƒu nghÄ©a, khÃ´ng chá»‰ keyword |
| **Intent Router** | LEGAL vs GENERAL, skip search khi khÃ´ng cáº§n |
| **Query Rewriting** | Biáº¿n follow-up thÃ nh standalone question |
| **Prompt Engineering** | IRAC structure, Chain-of-Thought, anti-hallucination |
| **LLM Factory** | Multi-provider, easy switching |

**Tiáº¿p theo:** Member 4 - Frontend, Database & Demo

*"Tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng nhÆ° tháº¿ nÃ o?"*

</LayoutTitleContent>
